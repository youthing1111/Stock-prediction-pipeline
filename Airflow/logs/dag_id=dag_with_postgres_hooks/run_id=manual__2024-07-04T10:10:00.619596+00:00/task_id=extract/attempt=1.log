[2024-07-04T10:10:01.721+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-07-04T10:10:01.730+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: dag_with_postgres_hooks.extract manual__2024-07-04T10:10:00.619596+00:00 [queued]>
[2024-07-04T10:10:01.733+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: dag_with_postgres_hooks.extract manual__2024-07-04T10:10:00.619596+00:00 [queued]>
[2024-07-04T10:10:01.733+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-07-04T10:10:01.738+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): extract> on 2024-07-04 10:10:00.619596+00:00
[2024-07-04T10:10:01.740+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=184) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-07-04T10:10:01.741+0000] {standard_task_runner.py:63} INFO - Started process 186 to run task
[2024-07-04T10:10:01.741+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'dag_with_postgres_hooks', 'extract', 'manual__2024-07-04T10:10:00.619596+00:00', '--job-id', '286', '--raw', '--subdir', 'DAGS_FOLDER/sql_2.py', '--cfg-path', '/tmp/tmp6hbrbhtm']
[2024-07-04T10:10:01.742+0000] {standard_task_runner.py:91} INFO - Job 286: Subtask extract
[2024-07-04T10:10:01.757+0000] {task_command.py:426} INFO - Running <TaskInstance: dag_with_postgres_hooks.extract manual__2024-07-04T10:10:00.619596+00:00 [running]> on host 73a0e5a00b20
[2024-07-04T10:10:01.787+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='***@example.com' AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='dag_with_postgres_hooks' AIRFLOW_CTX_TASK_ID='extract' AIRFLOW_CTX_EXECUTION_DATE='2024-07-04T10:10:00.619596+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-07-04T10:10:00.619596+00:00'
[2024-07-04T10:10:01.787+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-07-04T10:10:01.790+0000] {base.py:84} INFO - Using connection ID 'Postgres_server' for task execution.
[2024-07-04T10:10:01.800+0000] {python.py:237} INFO - Done. Returned value was:          OPEN   HIGH    LOW  CLOSE    VOLUME
0      9133.0   9133   8228   8228   4067100
1      7817.0   8310   7817   8146   2516207
2      7364.0   8393   7364   8228   1946700
3      8228.0   8310   8105   8228   3166000
4      8228.0   8516   8228   8310   3684800
...       ...    ...    ...    ...       ...
1000  27800.0  28000  26850  26850  19503800
1001  26850.0  27150  26750  27150  18350400
1002  27200.0  27250  26750  27650  12592201
1003  26600.0  26800  26450  26700  10171300
1004  23800.0  24000  23750  23800  13972830

[1005 rows x 5 columns]
[2024-07-04T10:10:01.807+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-07-04T10:10:01.846+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=dag_with_postgres_hooks, task_id=extract, run_id=manual__2024-07-04T10:10:00.619596+00:00, execution_date=20240704T101000, start_date=20240704T101001, end_date=20240704T101001
[2024-07-04T10:10:01.881+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-07-04T10:10:01.887+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-07-04T10:10:01.888+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
