import requests
import json
from pyspark.sql import SparkSession
from pyspark import SQLContext
from pyspark.sql import functions as F
from airflow.providers.postgres.hooks.postgres import PostgresHook
from airflow.models.connection import Connection

c = Connection(
    conn_id='postgres',
    conn_type='Postgres',
    login='airflow',
    password='airflow'
)

spark = SparkSession \
    .builder \
    .appName("DataExtraction") \
    .getOrCreate() 

hook = PostgresHook(postgres_conn_id="postgres")
sql_ts = """ SELECT * FROM public."acb_stock" """
df_old = hook.get_pandas_df(sql_ts)

